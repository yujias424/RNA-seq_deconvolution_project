# from DeconrnaseqMethod import deconrnaseq,deconrnaseqweight
import numpy as np
import pandas as pd
import h5py
import json
import subprocess
import os.path
import os

import cell_ontology as co

file_name = 'expression_CPM.h5'
decon_temp = './decon_temp/'
decon_temp_shell = "./decon_temp/"

######## HERE ARE SOME THINGS? eats up memory

cpm = h5py.File(file_name, 'r')
studies = np.array(cpm.get('study')).astype(str)
exp_acc = np.array(cpm.get('experiment_accession')).astype(str)
gene_ids = np.array(cpm.get('gene')).astype(str)
cpm.close()

with open('cell_types.json', 'r') as type_file:
    type_file = json.load(type_file)

study_dict = {}
for i in range(len(studies)):
    if studies[i] not in study_dict:
        study_dict[studies[i]] = [exp_acc[i]]
    else:
        study_dict[studies[i]].append(exp_acc[i])

######## FUNCTIONS FOR VIEWING / ANALYZING

def status_check(view_studies = False):
    """
    Prints number of studies deconvolved, number of studies pending, and a list
    of pending study ids.
    """
    study_set = set(studies)
    done = 0
    pending = 0
    pending_studies = []

    for study in study_set:
        exists = os.path.exists(decon_temp_shell + 'nonzero_' + study + '.tsv')
        if exists:
            done += 1
        else:
            pending += 1
            pending_studies.append(study)

    print("Done: {}, pending: {}".format(done, pending))
    if pending != 0 and view_studies == True:
        print(', '.join(pending_studies))

def get_exp_list(nonzero, study):
    acc_list = []

    for exp_acc in nonzero['0'].tolist():
        if exp_acc not in acc_list:
            acc_list.append(exp_acc) #uses order of experiments within file

    return acc_list

def study_view(study):
    """
    Returns a pandas dataframe of cell types in a study ranked from greatest to
    least. Good for viewing in a notebook.
    """
    print(study)
    nonzero = pd.read_csv(decon_temp + 'nonzero_'
            + study + '.tsv', sep = '\t')
    acc_list = get_exp_list(nonzero, study) # order of experiments in study

    type_list = [
            [co.get_term_name(celltype) for celltype in
            exp_to_celltypes(exp)] for exp in acc_list]
    type_list = ['; '.join(exp) for exp in type_list]

    view = []
    for exp in acc_list:
        exp_cells = []
        ll = 0
        for i in range(ll, len(nonzero['0'])):
            if nonzero['0'][i] == exp:
                exp_cells.append((nonzero['2'][i], nonzero['1'][i]))
                ll = i
        exp_cells.sort(reverse = True)
        view.append(exp_cells)

    view = pd.DataFrame(view, index = acc_list)
    view.insert(0, "labeled_type", type_list)

    return view

def read_results(ext):
    """
    Reads results tsv (generated by R) and returns a numpy array with contents.
    """
    # can be used to view results, but don't do that
    decon_fileNormal = decon_temp_shell + "results_Normal_" + ext + ".tsv"
    decon_fileWeight = decon_temp_shell + "results_Weight_" + ext + ".tsv"
    
    r_filepath = (decon_temp + 'results_'
                  + ext + '.tsv')
    resultsNormal = pd.read_csv(decon_fileNormal, sep = '\t', skiprows = 0)
    resultsWeight = pd.read_csv(decon_fileWeight, sep = '\t', skiprows = 0)

    return [resultsNormal,resultsWeight]

######## H5 FILE INFO

def get_signatures(index_list):
    """
    For a given list of indices in the file, returns a numpy array of
    gene signatures at those indices.
    """
    cpm = h5py.File(file_name, 'r')

    first = True
    for x in index_list:
        if first:
            signatures = cpm.get('cpm')[x]
            first = False
        else: # TODO: explain why you chose column stack
            b = np.array(cpm.get('cpm')[x])
            signatures = np.column_stack([signatures, b])

    cpm.close()
    return signatures

def get_accession(index_list):
    """
    For a given list of indices in the file, returns a list of experiment
    accession numbers.
    """
    acc_list = []
    for x in index_list:
        acc_list.append(exp_acc[x])

    return acc_list # used twice

def get_studies():
    return list(set(studies))

def get_exps():
    return exp_acc

def exp_to_index(exp):
    return np.where(exp_acc == exp)[0][0]

def study_to_exps(study):
    """
    Creates a dictionary with study ids as keys and accession numbers for
    experiments in study as values.
    """
    return study_dict[study] # unused

def exp_to_study(exp):
    index = exp_to_index(exp)
    study = studies[index]
    # currently gets very upset if exp_acc doesn't exist

    return study # unused

def celltype_to_exp(cell_type):
    exp_list = []
    for exp in exp_acc:
        if cell_type in exp_to_celltypes(exp): # Whether in is a good choice? Sometimes some exp contained more than 1 cell type will be calculated twice. 
            exp_list.append(exp)

    return exp_list # unused

def exp_to_celltypes(exp):
    """
    Gets specific labels for a given experiment.
    """
    type_ids = co.get_terms_without_children(type_file[exp])
    general_labels = ["CL:2000001", "CL:0000081", "CL:0002371", "CL:0000548",
            "CL:0000010"]
            # PBMC, blood cell, somatic cell, animal cell, cultured cell
            # making an executive decision to exclude these cell types
    specific_list = [id for id in type_ids if id not in general_labels]
    if len(specific_list) == 0: # if the only labels are "bad"
#         print("Shit")
        specific_list = type_ids #return original labels (some of which are bad)

    return specific_list # used 6 times

def ancestor_exps(celltype):
    celltypes = [celltype]
    celltypes += co.get_descendents(celltype)
    explist = []
    for celltype in celltypes:
        explist += celltype_to_exp(celltype)
    return explist

######## CREATE REFERENCE AND QUERY MATRICES

def create_reference(index_list):
    """
    Given a set of studies from which to draw from, creates a reference matrix.
    """
    cell_types = []
    for i in index_list:
        cell_types += exp_to_celltypes(exp_acc[i]) # TEST

    cell_types = list(set(cell_types))
    leaves = co.get_terms_without_children(cell_types)

    leaf_index = {}
    for leaf in leaves:
        leaf_index[leaf] = [exp_to_index(celltype) for celltype in celltype_to_exp(leaf)] # TEST

    # TODO: this could use some clarification
    # explain what's going on with column stack and why you picked it

    first = True
    for leaf in leaves:
        signatures = get_signatures(leaf_index[leaf])

        if len(leaf_index[leaf]) == 1:
            average = signatures
        else:
            average = np.mean(signatures, axis = 1)

        if first:
            a = average
            first = False
        else:
            a = np.column_stack([a, average])

    leaves = [co.get_term_name(leaf) for leaf in leaves]

    return {"gene_ids" : gene_ids,
            "reference" : a, "cell_types" : leaves}

def create_queries(query_list):
    """
    For a given list of indices in the file, returns a dictionary containing
    gene ids, query signatures, and experiment accession numbers.
    """
    query = get_signatures(query_list)
    exp_acc = get_accession(query_list)

    return {"query" : query, "gene_ids" : gene_ids,
                "experiment_accession" : exp_acc}

######## WRITE TSVS

def write_reference_tsv(index_list, ext):
    d = create_reference(index_list)
    r_filepath = (decon_temp + 'reference_'
                  + ext + '.tsv')
    reference_tsv = pd.DataFrame(d["reference"], index = d["gene_ids"],
                columns = d["cell_types"])
    reference_tsv.to_csv(r_filepath, sep = "\t")

    return d

def write_query_tsv(index_list, ext):
    d = create_queries(index_list)
    q_filepath = (decon_temp + 'query_'
                  + ext + '.tsv')
    query_tsv = pd.DataFrame(d["query"], index = d["gene_ids"],
                columns = d["experiment_accession"])
    query_tsv.to_csv(q_filepath, sep = "\t")

def write_tsvs(reference_list, query_list, ext):
    """
    Given a list of reference and query indices, writes reference and query
    tsvs. Returns a dictionary containing experiment accession numbers of query
    and cell types of reference.
    """
    r = write_reference_tsv(reference_list, ext)
    write_query_tsv(query_list, ext)

    return {"experiment_accession" : get_accession(query_list),
            "cell_types" : r["cell_types"]}

def study_nonzero(d):
    """
    Given a tsv of deconvolution results, writes a second tsv with only the
    nonzero proportions and their corresponding cell types.
    """
    # BUG: this breaks for single-experiment studies
    # gives an index error and I'm not sure why
#     n_filepath = (decon_temp + 'nonzero_'
#                   + d["study_id"] + '.tsv')

#     results_array = read_results(d["study_id"])
    
    for j in range(2):
        nonzero = []
        if j == 0:
            n_filepath = (decon_temp + 'nonzero_Normal_'
                  + d["study_id"] + '.tsv')
            r_filepath = (decon_temp + 'results_Normal_'
                  + d["study_id"] + '.tsv')
        else:
            n_filepath = (decon_temp + 'nonzero_Weight_'
                  + d["study_id"] + '.tsv')
            r_filepath = (decon_temp + 'results_Weight_'
                  + d["study_id"] + '.tsv')
        results_array = pd.read_csv(r_filepath, sep = '\t',index_col=0)
        results_array = np.array(results_array)
        a = np.nonzero(results_array) # TODO: this is not a descriptive variable name
        nonzero = []
        for i in range(len(a[0])):
            exp_acc = d["experiment_accession"][a[0][i]]
            cell_type = d["cell_types"][a[1][i]] # index error: list index out of range
            proportion = results_array[a][i]
            nonzero.append([exp_acc, cell_type, proportion])
        nonzero = pd.DataFrame(np.array(nonzero))
        nonzero.to_csv(n_filepath, sep = "\t")
            

######## HANDLE SINGLE-EXPERIMENT STUDIES

# TODO: clarify code (no more using 'a' as a variable name, idiot)
def trim_single_exp(study):
    """
    Deletes duplicate data in results tsv for single-experiment studies.
    """
    a = pd.read_csv(decon_temp + 'results_'
            + study + '.tsv', sep = '\t')
    a = a[:1]
    a.to_csv(decon_temp + 'results_'
            + study + '.tsv', sep = '\t')

######## OVERALL PIPELINE

def decon_study(study, test_dataset = False, TM = False,TrainedNoiseModel = None):
    """
    Deconvolutes given study and creates a tsv with results. Attempts to write
    a tsv with nonzero proportions.
    """
    cpm = h5py.File(file_name, 'r')
    ext = study # for ease of readability? not sure if it makes things more or
#     # less confusing
#     # TODO : perhaps split into multiple functions?
    if test_dataset:
        studies = np.array(cpm.get('study')).astype(str)[0:150]
    else:
        studies = np.array(cpm.get('study')).astype(str)
    cpm.close()

    a = set(studies) # set of all studies
    s = set([study]) # set with single element - study of interest
    m = a - s # set of all studies except study of interest

    # converts sets into lists of indices (artifact of old process)
    query_list = []
    reference_list = []
    for i in range(len(studies)):
        if studies[i] in m:
            reference_list.append(i)
        else:
            query_list.append(i)
    # handle single experiment-studies by duplicating query, as DeconRNASeq
    # requires at least two queries to run
    single_exp = len(query_list) == 1
    if single_exp:
        query_list *= 2

    # write tsvs, build dictionary
    info = write_tsvs(reference_list, query_list, ext)
    info["labeled_type"] = [
            [co.get_term_name(celltype) for celltype in
            exp_to_celltypes(exp_acc[i])] for i in query_list] # TEST
    info["study_id"] = study
    query_file = decon_temp_shell + "query_" + ext + ".tsv"
    reference_file = decon_temp_shell + "reference_" + ext + ".tsv"
    
    # return None
    decon_fileNormal = decon_temp_shell + "results_Normal_" + ext + ".tsv"
    decon_fileWeight = decon_temp_shell + "results_Weight_" + ext + ".tsv"
    
#     # Deconvolution
    result = deconrnaseq(query_file, reference_file, use_scale = False)
    result[0].to_csv(decon_fileNormal, sep="\t")
    
    if TM == True:
        result = deconrnaseqweight(query_file, reference_file, use_scale = False, Trainmodel = True, ProvideTM = TrainedNoiseModel)
        result[0].to_csv(decon_fileWeight, sep="\t")

    # delete duplicate query from results file
#     if single_exp:
#         trim_single_exp(ext)

    # generate nonzero tsv for each study. if successfully completed, delete
    # query and reference tsvs
    try:
        study_nonzero(info)
        os.remove(query_file)
        os.remove(reference_file)
    except IndexError:
        print(str(IndexError)) # TODO: get a better error message.
        # why does this print '<class IndexError>'?

    # I'm keeping this return statement for debugging purposes
    # TODO : delete eventually
    return info

def decon_studies(test = False):
    """
    Loops through all studies in file and deconvolutes each.
    """
    if test: # only looks at first 150 studies, goes faster
        dataset = studies[0:150]
    else:
        dataset = studies
    dataset = set(dataset) # removes duplicates, order doesn't matter

    # ensures that already deconvolved studies don't get re-done
    for study in dataset:
        if os.path.exists(decon_temp_shell + 'nonzero_' + study + '.tsv'):
            continue
        elif os.path.exists(decon_temp_shell + 'results_' + study + '.tsv'):
            # index error was previously thrown
            print("An IndexError was previously thrown for {}.".format(study))
            continue
            # TODO: figure out how to fix the index error and put that here?
            # this is only a temporary edge case but it's frustrating
        else:
            print(study)
            d = decon_study(study, test)